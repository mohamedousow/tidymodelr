---
title: "IDL3 :Machine learning avec tidymodels "
author: "Dr. Mohamedou SOW"
date: "`r Sys.Date()`"
lang: fr-FR
execute: 
  warning: false
format: 
  html:
    df-print: kable
    number-sections: true
    toc: true
    code-fold: true
editor: visual
editor_options: 
  chunk_output_type: console
---



## Introduction  

Tidymodels est un métapackage, une collection de packages pour la modélisation et l'apprentissage automatique utilisant les principes de tidyverse. Il offre une approche unifiée et cohérente pour la modélisation statistique, facilitant le prétraitement des données, l'ajustement des modèles et l'évaluation des performances.


## Objectif

Comment prédire si une tumeur mammaire est maligne ou bénigne ? (Problème de classification)

Le but est de développer un modèle qui permet de prédire si une tumeur mammaire est maligne ou bénigne en fonction des mesures de la taille et de la forme des cellules.


## Données

Les informations pour la démonstration proviennent du dépôt de machine learning de l'Université de Californie à Irvine (UCI).

Il s'agit de la base de données sur le cancer du sein au Wisconsin 
<https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic>   

- Les variables  

1) Numéro d'identification
2) Diagnostic (M = maligne, B = bénigne)
3-32)

Dix caractéristiques à valeur réelle sont calculées pour chaque noyau cellulaire :

	a) rayon (moyenne des distances entre le centre et les points du périmètre)
	b) texture (écart-type des valeurs en niveaux de gris)
	c) périmètre
	d) surface
	e) douceur (variation locale de la longueur des rayons)
	f) compacité (périmètre^2 / surface - 1,0)
	g) concavité (gravité des parties concaves du contour)
	h) points concaves (nombre de parties concaves du contour)
	i) symétrie 
	j) dimension fractale (« approximation du trait de côte » - 1)
	
Pour en savoir plus sur l’ensemble de données du Wisconsin sur le cancer du sein, et plus particulièrement sur la manière dont chacune des caractéristiques de cet ensemble de données a été calculée, veuillez consulter :

Street, W.N., Wolberg, W.H., & Mangasarian, O.L. (1993). Nuclear feature extraction for breast tumor diagnosis. Electronic imaging.

### Installation et Chargement des librairies

```{r}
# test et installation de tidymodels
if (!require("tidymodels")) {
  # Si elle n'est pas installée, installer la bibliothèque
  install.packages("tidymodels")
}
```


```{r}
# Chargement des  packages
library(tidyverse)
library(tidymodels)
library(ggcorrplot)
library(caret)
```


```{r}
# Lecture des données
data <- read.csv("data/data.csv")
str(data)
```

### Prétraitement des données et analyse des variables

- Recodage de la variable cible

```{r}
df1 <- data |> dplyr::mutate(diagnosis = ifelse(diagnosis=="M", 1, 0))
str(df1)
```


```{r}
# On retire la variable X qui est constituée que des NA et id qui n'apporte pas d'infos pour la prédiction
df <- df1 |> select(-id, -X)
```

```{r}
# Transformation de la colonne "diagnosis" en facteur
df <- df|> dplyr::mutate(diagnosis = as.factor(diagnosis))
```

```{r}
# description des variables 
df |> skimr::skim()
```

```{r}
# Vérification des NA
any(is.na(df))
# Vérifier les colonnes qui ont des valeurs NA
#colSums(is.na(df))
```

```{r}
# diagramme à barres
ggplot(df, aes(x=diagnosis, fill= diagnosis)) +
geom_bar(stat="count") +
theme_classic() +
scale_y_continuous(breaks = seq(0, 400, by = 25)) +
labs(title="Distribution de la variable cible: Diagnostic") +
 scale_fill_manual(labels = c("Bénigne", "Maligne"), values = c("dodgerblue1","red3"))
  
```

```{r}
fig2 <- df[c("radius_mean", "diagnosis")]
# box plot
ggplot(fig2, aes(diagnosis, radius_mean, fill = diagnosis)) + 
  geom_boxplot()+
  labs(col="Type de tumeur") + ylab("lobes radius mean") +
labs(title="Box plot du rayon moyen de lobes en fonction de la varibale cible")+
  scale_fill_manual(labels = c("Bénigne", "Maligne"), values = c("dodgerblue1","red3")) + theme_classic()
```



```{r}
# Corrélation entre les différentes variables quantitatives
ggcorrplot(cor(df[,-1]),tl.cex  = 9,tl.srt = 50,title = "Correlation heat-map")
```



### Partiion du jeu de données en apprentissage et test

- On utilise le package 'rsample' pour séparer notre jeu de données en deux 
```{r}
set.seed(42)
# tirage stratifié 
split_r <- df |> rsample::initial_split(prop = 0.7, strata = diagnosis) 
print(split_r)

```

```{r}
# Création des échantillons d'apprentissage et de test
dtrain <- rsample::training(split_r)
dtest <- rsample::testing(split_r)
# affichage des effectifs

print(dim(dtrain))
print(dim(dtest))
```
```{r}
# Proportion de bénigne et maligne dans train
dtrain |> dplyr::count(diagnosis) |> dplyr::mutate(freq_rel = prop.table(n))
# Proportion de bénigne et maligne dans test
dtest |> dplyr::count(diagnosis) |> dplyr::mutate(freq_rel = prop.table(n))
```


```{r}

# Table et proportions pour Diagnostic (M = maline, B = bénigne)
diagTab <- table(df$diagnosis)
prop_diag <- round(prop.table(diagTab)*100, 2)
labels <- paste(names(diagTab), "\n", prop_diag, "%", sep = "")
# Diagramme en camembert avec proportions
par(mfrow=c(1, 3))
pie(diagTab, labels = labels, main = "Ensemble du jeu de données: B/M", col = c("red", "green"))

diagTab <- table(dtrain$diagnosis)
prop_diag <- round(prop.table(diagTab)*100, 2)
labels <- paste(names(diagTab), "\n", prop_diag, "%", sep = "")
# Diagramme en camembert avec proportions
pie(diagTab, labels = labels, main = "Entrainement: B/M", col = c("red", "green"))

diagTab <- table(dtest$diagnosis)
prop_diag <- round(prop.table(diagTab)*100, 2)
labels <- paste(names(diagTab), "\n", prop_diag, "%", sep = "")
# Diagramme en camembert avec proportions
pie(diagTab, labels = labels, main = "Test:B/M", col = c("red", "green"))

```


## Modélisation et évaluation



### Choix de l'algorithme d'apprentissage

- Utilisation du package R 'brulee' basé sur torch
- Construction d'un modèle régression logistique (perceptron simple)

```{r}
# les moteurs de calculs sont dans parsnip
parsnip::show_engines('logistic_reg')
```

Pour notre régression logistique nous allons Instancier un modèle basée sur le moteur de calcul 'brulee' pour faire de la classification supervisé
```{r}
# Définition des algos d'apprentissage basée sur la régression logistique 

model_lr <-  parsnip::logistic_reg() |> 
  parsnip::set_engine('brulee') |>
  parsnip::set_mode('classification')

```

```{r}
#recipe permet de préparer les données dans le workflow 
lr_recipe = recipe(diagnosis ~ ., data = dtrain) %>% 
  #normalisation des données 
            step_normalize(all_numeric(), -all_outcomes()) %>% 
     #retrait des variables fortement corrélées
             step_corr(all_numeric(), -all_outcomes(),threshold = 0.9)
 
#  Il nous reste 19 prédicteurs sur 30
model_train_data = lr_recipe %>% prep() %>% bake(dtrain) 
```


### Définition du workflow d'apprentissage

```{r}
# Définir le workflow et spécifier le modèle 
processus_lr <- workflows::workflow() |> 
  workflows::add_model(model_lr) |>
  workflows::add_recipe(lr_recipe) 
```


### Modélisation et inspection du modèle

- Lancement du processus d'apprentissage

```{r}
# apprentissage
lr_fit <- processus_lr |> fit(dtrain)
print(lr_fit)
```



```{r}
# instance du modèle fitée (fit)
lr_obj <- workflows::extract_fit_parsnip(lr_fit)
lr_obj <- lr_obj$fit
class(lr_obj)
```



```{r}
#dev.off()
# évolution du 'loss'  durant l’entraînement 

plot(lr_obj$loss, type = 'b', main='Evolution de la loss')
```

```{r}
# affichage  des derniers coefficients
lr_obj$estimates[[length(lr_obj$estimates)]]
```

## Prédiction et évaluation en test

```{r}
# Prédiction en test
pred_test <- lr_fit |>
  predict(dtest) |>
  bind_cols(true_class=dtest$diagnosis)

pred_test |> head()
```
- Matrice de confusion
```{r}
# Matrice de confusion, conf_mat se trouve dans yardstick
mat_c <- pred_test |> 
  yardstick::conf_mat(truth = true_class, estimate = .pred_class)

autoplot(mat_c, type = "heatmap") +
  scale_fill_gradient(low="#D6EAF8",high = "#2E86C1") +
  theme(legend.position = "right") + labs(title = "Matrice de Confusion modèle régression logistique/brulee")
```


```{r}
# Mesures des performances du modèle
mesures <- yardstick::metric_set(accuracy)
# classe de l'objet
class(mesures)
```

```{r}
pred_test |> mesures(truth = true_class, estimate = .pred_class)
```



## Comparaison avec K-Nearest Neighbor (KNN) 

```{r}
# utilisation de la validation croisée
train_control <- trainControl(method="cv", number=10)
```


```{r}
# Entrainement du modèle
model1 <- train(diagnosis~., data=dtrain, trControl=train_control,
method="knn")
predictions1<-predict(model1, newdata = dtest)

```


```{r}
# graphique du modèle
plot(model1)
```

```{r}
# Matrice de confusion
cm1<-confusionMatrix(predictions1,dtest$diagnosis, positive = "1") 
cm1
```


```{r}
# graphique de la matrice de confusion
cm1_plot <- data.frame(predictions1,dtest$diagnosis )
names(cm1_plot) <- c("Predit", "reel")


cm1_plot <- conf_mat(cm1_plot,  reel,Predit)
autoplot(cm1_plot, type = "heatmap") +
  scale_fill_gradient(low="#D6EAF8",high = "#2E86C1") +
  theme(legend.position = "right") + labs(title = "Matrice de Confusion pour KNN model")
```

